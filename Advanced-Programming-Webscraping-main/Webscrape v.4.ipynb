{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import openpyxl\n",
    "import time\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Companies-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel spreadsheet containing the list of company names\n",
    "wb = openpyxl.load_workbook('/Users/lucas/Documents/Babson/23Programming/Webscrap/companies.xlsx')\n",
    "sheet = wb.active\n",
    "\n",
    "# Specify the starting and ending rows (inclusive)\n",
    "start_row = 2\n",
    "end_row = 3\n",
    "\n",
    "# Create a new workbook to store the results\n",
    "result_wb = openpyxl.Workbook()\n",
    "result_ws = result_wb.active\n",
    "result_ws.append(['Company Name', 'Staff Name', 'Title', 'Company Address'])\n",
    "\n",
    "# Open a new Chrome browser window and navigate to the website\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://corp.sec.state.ma.us/corpweb/CorpSearch/CorpSearch.aspx')\n",
    "\n",
    "# Find the input field for company names and loop through each company in the specified range of rows\n",
    "input_field = driver.find_element_by_css_selector('#MainContent_txtEntityName')\n",
    "for row in sheet.iter_rows(min_row=start_row, max_row=end_row, max_col=1):\n",
    "    company_name = row[0].value\n",
    "    input_field.clear()\n",
    "    input_field.send_keys(company_name)\n",
    "    input_field.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Wait for the search results page to load\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # Click on the first link to go to the company details page\n",
    "    link = driver.find_element_by_css_selector('#MainContent_SearchControl_grdSearchResultsEntity > tbody > tr:nth-child(2) > th > a')\n",
    "    link.click()\n",
    "\n",
    "    # Wait for the company details page to load\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # Get the company name from the details page\n",
    "    company_name = driver.find_element_by_css_selector('#MainContent_lblEntityNameHeader').text.strip()\n",
    "\n",
    "    # Get the table of staff names and save it to the result workbook\n",
    "    try:\n",
    "        table = driver.find_element_by_css_selector('#MainContent_grdOfficers')\n",
    "        rows = table.find_elements_by_tag_name('tr')\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_elements_by_tag_name('td')\n",
    "            th_col = row.find_element_by_tag_name('th')\n",
    "            title = th_col.text\n",
    "            staff_name = cols[0].text\n",
    "            address = cols[1].text\n",
    "            result_ws.append([company_name, staff_name, title, address])\n",
    "    except:\n",
    "        print(f\"An error occurred while processing {company_name}. Moving on to the next company.\")\n",
    "\n",
    "    # Go back to the search page to search for the next company\n",
    "    driver.get('https://corp.sec.state.ma.us/corpweb/CorpSearch/CorpSearch.aspx')\n",
    "    input_field = driver.find_element_by_css_selector('#MainContent_txtEntityName')\n",
    "\n",
    "# Save the result workbook\n",
    "result_wb.save('results.xlsx')\n",
    "\n",
    "# Close the browser window\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN WEBSCRAPING 1\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('results.xlsx')\n",
    "\n",
    "# Split the Staff Name column into first_name and last_name columns\n",
    "df['first_name'] = df['Staff Name'].str.split(' ').str[0]\n",
    "df['last_name'] = df['Staff Name'].str.split(' ').str[-1]\n",
    "df = df[['first_name', 'last_name', 'Staff Name', 'Title', 'Company Address']]\n",
    "\n",
    "# Save the modified DataFrame as a new Excel file\n",
    "df.to_excel('results-cleaned.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executives-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the website and the path to the Excel file\n",
    "url = \"https://corp.sec.state.ma.us/corpweb/CorpSearch/CorpSearch.aspx\"\n",
    "excel_file = \"results-cleaned.xlsx\"\n",
    "output_file = \"results-executives.csv\"\n",
    "\n",
    "# Set up the web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Read the Excel file and search for each name on the website\n",
    "workbook = openpyxl.load_workbook(excel_file)\n",
    "worksheet = workbook.active\n",
    "header_row = [\"first_name\", \"last_name\", \"title\", \"executive_address\", \"business_entity\", \"id_no\", \"old_id_no\"]\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\") as out_f:\n",
    "    writer = csv.writer(out_f)\n",
    "    writer.writerow(header_row)  # write header row\n",
    "\n",
    "    for row in worksheet.iter_rows(min_row=2, min_col=1, max_col=2):\n",
    "        first_name, last_name = [cell.value for cell in row]\n",
    "\n",
    "        # Navigate to the website and click on the radio button for individual search\n",
    "        driver.get(url)\n",
    "        driver.find_element_by_css_selector(\"#MainContent_rdoByIndividual\").click()\n",
    "\n",
    "        # Wait for the page to load\n",
    "        WebDriverWait(driver, 10).until(EC.staleness_of(driver.find_element_by_css_selector(\"#MainContent_tblByIndividual\")))\n",
    "\n",
    "        # Enter the first name and last name in the appropriate fields\n",
    "        driver.find_element_by_css_selector(\"#MainContent_txtFirstName\").send_keys(first_name)\n",
    "        driver.find_element_by_css_selector(\"#MainContent_txtLastName\").send_keys(last_name)\n",
    "\n",
    "        # Click on the search button\n",
    "        driver.find_element_by_css_selector(\"#MainContent_btnSearch\").click()\n",
    "\n",
    "        # Wait for the search results to load and extract them\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.staleness_of(driver.find_element_by_css_selector(\"#MainContent_SearchControl_tblGrid1\")))\n",
    "            search_results = driver.find_elements_by_css_selector(\"#MainContent_SearchControl_tblGrid1 tr\")\n",
    "            for result in search_results[1:]:  # skip header row\n",
    "                row_data = [first_name, last_name]\n",
    "                columns = result.find_elements_by_tag_name(\"td\")\n",
    "                for column in columns:\n",
    "                    row_data.append(column.text)\n",
    "                writer.writerow(row_data + [\"\"])\n",
    "        except:\n",
    "            # handle any errors that occur while waiting for the search results to load\n",
    "            writer.writerow([first_name, last_name, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Error\"])\n",
    "\n",
    "        # Return to the original page to perform a new search\n",
    "        driver.get(url)\n",
    "\n",
    "        # Add a delay of 5 seconds between each search\n",
    "        time.sleep(5)\n",
    "\n",
    "# Close the web driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
